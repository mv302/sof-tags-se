{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 19:18:52.243421: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-16 19:18:52.283029: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 19:18:52.490759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-16 19:18:52.490938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-16 19:18:52.522157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-16 19:18:52.601782: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 19:18:52.603683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 19:18:53.303098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mv/.local/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/mv/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_19871/2504795971.py:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "[[['[PAD]', '[unused0]', '[unused2]', '[unused1]', '[unused3]']]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the pretrained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
    "\n",
    "def generate_tags(question):\n",
    "    # Preprocess the question\n",
    "    encoded_text = tokenizer(question, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate tags using the pretrained model\n",
    "    with tf.device(\"/gpu:0\" if tf.test.is_gpu_available() else \"/cpu:0\"):\n",
    "        outputs = model(**encoded_text)\n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "\n",
    "    # Get the top 5 tags\n",
    "    top_5_tags = logits.argsort(axis=1)[:, -5:]\n",
    "\n",
    "    # Convert tag indices to tag names\n",
    "    tags_list = [[tokenizer.convert_ids_to_tokens(tags_idx)] for tags_idx in top_5_tags]\n",
    "\n",
    "\n",
    "    return tags_list\n",
    "\n",
    "\n",
    "# Example usage\n",
    "question = \"\"\"What is the use of the yield keyword in Python? What does it do?\n",
    "\n",
    "For example, I'm trying to understand this code1:\n",
    "\n",
    "def _get_child_candidates(self, distance, min_dist, max_dist):\n",
    "    if self._leftchild and distance - max_dist < self._median:\n",
    "        yield self._leftchild\n",
    "    if self._rightchild and distance + max_dist >= self._median:\n",
    "        yield self._rightchild  \n",
    "And this is the caller:\n",
    "\n",
    "result, candidates = [], [self]\n",
    "while candidates:\n",
    "    node = candidates.pop()\n",
    "    distance = node._get_dist(obj)\n",
    "    if distance <= max_dist and distance >= min_dist:\n",
    "        result.extend(node._values)\n",
    "    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))\n",
    "return result\n",
    "What happens when the method _get_child_candidates is called? Is a list returned? A single element? Is it called again? When will subsequent calls stop?\"\"\"\n",
    "tags = generate_tags(question)\n",
    "print(tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
